{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: Topics, Documents, Relevance Judgments\n",
    "\n",
    "Some cool description ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load('iranthology')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: View all Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQuery(query_id='1', title='social media detect self-harm', description=\"Which papers focus on how to recognize signs of self-harm in people's social media posts?\", narrative='Relevant papers include research on early detection of self-harm on social media platforms such as Facebook, Instagram, Reddit, Twitter and co. Papers that addresses mental health issues like depression or anorexia are not relevant. Furthermore, papers that deal with self-harm but are not related to social media are also not relevant.')\n",
      "TrecQuery(query_id='2', title='recommendation systems', description='What documents contain information on recommendation systems (systems that suggest items to users based on their past behaviour and interests)', narrative='Relevant documents contain information or research on the topic of recommendation systems in the context of information retrieval.')\n",
      "TrecQuery(query_id='3', title='machine learning for more relevant results', description='Which papers describe methods to find more relevant results using machine learning?', narrative='Relevant papers describe one or more methods to find more relevant results using machine learning. Papers about just machine learning in IR in general or papers just about finding more relevant results are not relevant.')\n",
      "TrecQuery(query_id='4', title='misspellings in queries', description='Find papers that describe algorithms or datasets for automatic query spelling correction?', narrative='Relevant Information Retrieval documents cover the topic of misspellings in search engine queries and how to automatically correct them. Documents containing only the words \"queries\" or \"in\" are not relevant.')\n",
      "TrecQuery(query_id='5', title='filter ad rich documents', description='Find papers that describe how (affiliate) spam documents can be classified and removed in the ranking of a search engine.', narrative='Relevant documents cover how spam documents (with tons of ads and pop ups) can be classified and/or removed from search results.')\n"
     ]
    }
   ],
   "source": [
    "for query in dataset.queries_iter():\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: View first relevance judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='1', doc_id='2020.ipm_journal-ir0anthology0volumeA57A6.40', relevance=0, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "for qrel in dataset.qrels_iter():\n",
    "    print(qrel)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Show the document from above, does the relevance label make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IrAnthologyDocument(doc_id='2020.ipm_journal-ir0anthology0volumeA57A6.40', abstract='', title='Effect of anger, anxiety, and sadness on the propagation scale of social media posts after natural disasters', authors=['Lifang Li', 'Zhiqiang Wang', 'Qingpeng Zhang', 'Hong Wen'], year='2020', booktitle='2020 Volume 57 Issue 6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.docs_store().get('2020.ipm_journal-ir0anthology0volumeA57A6.40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Measure for Each topic the proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>Proportion Relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>social media detect self-harm</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>recommendation systems</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>machine learning for more relevant results</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>misspellings in queries</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>filter ad rich documents</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                       query  Proportion Relevant\n",
       "0   1               social media detect self-harm             0.363636\n",
       "1   2                      recommendation systems             0.977273\n",
       "2   3  machine learning for more relevant results             0.444444\n",
       "3   4                     misspellings in queries             0.228571\n",
       "4   5                    filter ad rich documents             0.023256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def proportion_relevant(topic_num):\n",
    "    rel, non_rel = 0, 0\n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == str(topic_num):\n",
    "            rel += 1 if qrel.relevance else 0\n",
    "            non_rel += 0 if qrel.relevance else 1\n",
    "    return rel / (rel + non_rel)\n",
    "\n",
    "df = []\n",
    "for query in dataset.queries_iter():\n",
    "    df += [{'qid': query.query_id, 'query': query.title, 'Proportion Relevant': proportion_relevant(query.query_id)}]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Analyse each topic and analyse for each topic positive and negative aspects and conclude for each topic if you would include or exclude it from subsequent evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One topic is too easy, everything is relevant => exclude\n",
    "- One topic is too difficult, nothing is relevant. The topic is only difficult because of the query formulation => exclude\n",
    "- 3 topics are good => include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create Your own Topic\n",
    "\n",
    "... here some advice ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Assess Judgment Pool for your Topic\n",
    "\n",
    "... Tutors provide you with the pools that you judge in doccano ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Analyse your topic\n",
    "\n",
    "... Compare it with your analysis from the 5 topics above ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
